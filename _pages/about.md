---
permalink: /
# title: "Overview " # ([Curriculum Vitae](https://lijian.ac.cn/files/cv/UCAS_PhD_lijian.pdf))
# excerpt: "Overview"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

I am an Associate Professor and Master's supervisor at the Institute of Information Engineering, Chinese Academy of Sciences (CAS), working on large-scale statistical learning theory and large language models (LLMs).
In July 2020, I obtained my Ph.D. degree from Institute of Information Engineering, CAS, advised by Associate Prof. [Yong Liu](https://liuyonggsai.github.io/) and Prof. Weiping Wang. 

To address the limited theoretical interpretability of large-scale machine learning algorithms, my focus lies in researching the foundational theoretical guarantees of large language models and other large-scale machine learning algorithms. I aim to enhance algorithms guided by theoretical findings, thereby reducing the gap between foundational theory and practical implementation. My research interests encompass but are not limited to:
* **LLMs and Deep Learning Theory**: theoretical studies on the unique capabilities of large language models (such as emergent abilities and grokking), as well as benign overfitting or the double descent phenomenon in deep learning.
* **Efficient LLMs**: efficient Transformers, compressed LLMs, and parameter-efficient fine-tuning (PEFT).
* **Large-scale Machine Learning**: statistical guarantees and improved algorithms for large-scale machine learning methods, including federated learning, distributed learning, random features, Nystr√∂m methods, sketching, etc.

## Curriculum Vitae ([CV](https://lijian.ac.cn/files/cv/cv_lijian_2023_en.pdf))

| Time               | Title                                                       | Institution                               | Research Direction                                    |
|:-------------------| :---------------------------------------------------------- | :---------------------------------------- | :---------------------------------------------------- |
| 2023.11 - present  | Associate Professor | Institute of Information Engineering, CAS | LLMs, Large-scale Statistical Machine Learning  |
| 2020.09 - 2023.11  | Tenure-track Professor     | Institute of Information Engineering, CAS | Large-scale Statistical Machine Learning              |
| 2015.09 - 2020.06  | Ph.D. Candidate                                             | Institute of Information Engineering, CAS | Large-scale Model Selection, Semi-supervised Learning |
| 2011.09 - 2015.06  | Bachelor Candidate                                          | Northeastern University                   | Software Engineering (International class)            |

## Selected Papers [[Full List](https://lijian.ac.cn/publications/)] [[Google Scholar](https://scholar.google.com/citations?hl=en-us&user=IAJpTqYAAAAJ&view_op=list_works&sortby=pubdate)] 
<i>* corresponding author</i>
## Preprint

* A Survey on Model Compression for Large Language Models.
[[pdf]](https://arxiv.org/abs/2308.07633) <br>
Xunyu Zhu, <u><b>Jian Li*</b></u>, Yong Liu, Can Ma, Weiping Wang.  <br>
<i> arXiv:2308.07633</i>. 

### Journal Papers

* Optimal Convergence Rates for Distributed Nystr√∂m Approximation. 
[[pdf]](https://jmlr.org/papers/volume24/21-1049/21-1049.pdf)
[[code]](https://github.com/superlj666/DNystroem) <br>
<u><b>Jian Li</b></u>, Yong Liu, Weiping Wang. <br>
<i>Journal of Machine Learning Research</i> (**JMLR**), 2023. <b>CCF-A</b>.

* Optimal Convergence for Agnostic Kernel Learning With Random Features.
[[pdf]](https://ieeexplore.ieee.org/abstract/document/10304308)
[[code]](https://github.com/superlj666/Agnostic-RF) <br>
<u><b>Jian Li</b></u>, Yong Liu, Weiping Wang.  <br>
<i>IEEE Transactions on Neural Networks and Learning Systems</i> (**TNNLS**), 2023. <b>CCF-B</b>.

* Semi-supervised vector-valued learning: Improved bounds and algorithms. 
[[pdf]](https://www.sciencedirect.com/science/article/pii/S0031320323000572) <br>
<u><b>Jian Li</b></u>, Yong Liu, Weiping Wang.  <br>
<i>Pattern Recognition</i> (**PR**), 2023. <b>CCF-B</b>.

* Improving Differentiable Architecture Search via Self-distillation.
[[pdf]](https://doi.org/10.1016/j.neunet.2023.08.062) <br>
Xunyu Zhu, <u><b>Jian Li*</b></u>, Yong Liu, Weiping Wang.  <br>
<i>Neural Networks</i>, 2023. <b>CCF-B</b>.

* Convolutional Spectral Kernel Learning with Generalization Guarantees.
[[Paper]](https://doi.org/10.1016/j.artint.2022.103803)
[[Code]](https://github.com/superlj666/CSKN/) <br>
<u><b>Jian Li</b></u>, Yong Liu, Weiping Wang. <br>
<i>Artificial Intelligence</i> (**AIJ**), 2022. <b>CCF-A</b>.

* Non-IID Federated Learning with Sharper Risk Bound.
[[pdf]](https://doi.org/10.1109/TNNLS.2022.3213187) <br>
Bojian Wei, <u><b>Jian Li*</b></u>, Yong Liu, Weiping Wang.  <br>
<i>IEEE Transactions on Neural Networks and Learning Systems</i> (**TNNLS**), 2022. <b>CCF-B</b>.

### Conference Papers

* Optimal Convergence Rates for Agnostic Nystr√∂m Kernel Learning.
[[pdf]](https://openreview.net/forum?id=S3d9SwhRKh) <br>
<u><b>Jian Li</b></u>, Yong Liu, Weiping Wang. <br>
<i>International Conference on Machine Learning </i> (**ICML**), 2023. <b>CCF-A</b>.

* Towards Sharp Analysis for Distributed Learning with Random Features. [[pdf]](https://www.ijcai.org/proceedings/2023/0436.pdf) <br>
<u><b>Jian Li</b></u>, Yong Liu. <br>
<i>International Joint Conference on Artificial Intelligence</i> (**IJCAI**), 2023. <b>CCF-A</b>.

* Ridgeless Regression with Random Features.
[[pdf]](https://www.ijcai.org/proceedings/2022/0445.pdf)
[[code]](https://github.com/superlj666/Ridgeless-Regression-with-Random-Features) <br>
<u><b>Jian Li</b></u>, Yong Liu, Yingying Zhang. <br>
<i>International Joint Conference on Artificial Intelligence</i> (**IJCAI**), 2022. <b>CCF-A</b>.

* Federated learning for non-iid data: From theory to algorithm. 
[[pdf]](https://link.springer.com/chapter/10.1007/978-3-030-89188-6_3)
[[presentation]](https://lijian.ac.cn/files/2021/FL_for_noniid_data_presentation.pdf)
[[üèÜ<b>Best student paper award</b>]](https://lijian.ac.cn/files/2021/PRICAI-2021-best-student-paper.png) <br>
Bojian Wei, <u><b>Jian Li*</b></u>, Yong Liu, Weiping Wang. <br>
<i>Pacific Rim International Conference on Artificial Intelligence</i> (**PRICAI**), 2021. CCF-C.

* Automated Spectral Kernel Learning. 
[[pdf]](https://ojs.aaai.org/index.php/AAAI/article/view/5892)
[[poster]](https://lijian.ac.cn/files/2020_AAAI_ASKL/2020_AAAI_AKSL_poster.pdf)
[[code]](https://github.com/superlj666/Automated-Spectral-Kernel-Learning) <br>
<u><b>Jian Li</b></u>, Yong Liu, Weiping Wang. <br>
<i>AAAI Conference on Artificial Intelligence</i> (**AAAI**), 2020. <b>CCF-A</b>.

* Multi-Class Learning: From Theory to Algorithm. 
[[pdf]](https://proceedings.neurips.cc/paper/2018/file/1141938ba2c2b13f5505d7c424ebae5f-Paper.pdf)
[[poster]](https://lijian.ac.cn/files/2018_NeurIPS_MC/mc-lrc-nips-poster.pdf)
[[sildes]](https://lijian.ac.cn/files/2018_NeurIPS_MC/mc-lrc-nips-slides.pdf)
[[3-minute video]](https://youtu.be/mE_RpgWuKK8)
[[code]](https://github.com/superlj666/Multi-Class-Learning-From-Theory-to-Algorithm) <br>
<u><b>Jian Li</b></u>, Yong Liu, Rong Yin, Hua Zhang, Lizhong Ding, Weiping Wang. <br>
<i>Advances in Neural Information Processing Systems 31</i> (**NeurIPS**), 2018. <b>CCF-A</b>.

##  Projects
* China Postdoctoral Science Foundation (No. 2023T160680), 2023.07 - 2024.03, &yen;180,000. <br>
<i>Research on Deep Differentiable Gaussian Processes for Structured Prediction</i>.

* National Key R&D Program of China (2022YFB3105302.2), 2022.12 - 2025.11, &yen;1,200,000. <br>
<i> Aggregation and Collaborative Techniques for Cross-platforms Heterogenous Data</i>.

* National Natural Science Foundation of China (No. 62106257), 202201 - 2024.12, &yen;300,000. <br>
<i> Large Scale Structured Prediction with Automated Spectral Kernel Learning</i>.

* Special Research Assistant Project of CAS, 2020.09 - 2022.09, &yen;800,000. <br>
<i> Large-scale Few-shot Automated Machine Learning</i>.

* Talent Program Class A of Institute of Information Engineering, CAS, Tenure-track Professor, 2023.11 - 2026.09.

* Talent Program Class B of Institute of Information Engineering, CAS, Tenure-track Young Professor, 2020.09 - 2023.11.


## Patents

### Pending

* <u><b>Jian Li</b></u>, Yong Liu, Liubin Wang, Yiguo Yang, Juhong Wang.Neural Network Architecture Search Method, Device, Computer Equipment, and Storage Medium. CNÔºö202011567991.3. App. Date: December 25, 2020.
* <u><b>Jian Li</b></u>, Jiaoyang Li, Bojian Wei, Yong Liu, Weiping Wang. A Federated Learning Method and System Based on Attention Mechanism. CN: 202311073645.3. App. Date: August 24, 2023
* <u><b>Jian Li</b></u>, Jiaoyang Li, Zheng Lin, Yong Liu, Weiping Wang. A Vertical Domain Large Model Method and System Based on Knowledge Distillation and Prompt Engineering. CN: 202311073641.5. App. Date: August 24, 2023.

### Granted

* Hailun Lin, Yong Liu, <u><b>Jian Li</b></u>, Weiping Wang. A Large-Scale Ontology Merging Method that Integrates Representation Learning and Divide-and-Conquer Strategy: China. Granted No.CN110059194A. Granted Date: April 8, 2022.


## Students
- Ph.D. students
  - üéìYilin Kang (2020.09 - 2023.06 ), Differential Privacy. Papers: Computers & Security, CIKM 2022, ICCS 2023. Post-graduation: Researcher in Purple Mountain Laboratories.
  - Xunyu Zhu (2020.09 - present), Neural Architecture Search. Papers: ICDM 2021.
  - Boxuan Che (2022.09 - present), Efficient Graph Neural Networks.
- Master's students
  - üéìBojian Wei (2020.09 - 2022.06), Federated Learning on Heterogenous Data. Papers: PRICAI 2021 (**best student paper award**), ECML-PKDD 2022, TNNLS, IJCNN 2023. Post-graduation: Management Trainee in Bank of China Head Office.
  - Xuning Zhang (2022.09 - present), Federated Learning. **Excellent Bachelor's Thesis in Wuhan University in 2023**.

## Honors and Awards
* PRICAI 2021 best student paper award, 2021.
* Outstanding Graduate of Institute of Information Engineering, CAS, 2021.
* Outstanding Graduates of Beijing, 2020.
* Outstanding Graduates of University of Chinese Academy of Sciences (UCAS), 2020.
* Outstanding Graduates of Institute of Information Engineering, CAS, 2020.
* National Scholarship for Doctoral students, 2019.
* ZhuLiYueHua Scholarship for Excellent Doctoral Student, 2019.
* CAS Presidential Scholarship, 2019.
* National Scholarship for Doctoral students, 2018.
* IIE Presidential Scholarship, 2018.

## Academic Service
* Mathematics Guest Editor
* Program committee of Conference: ICML, NeurIPS, ICLR, AAAI, IJCAI, ECAI, etc.
* Reviewers of Journals: TPAMI, JMLR, Pattern Recognition, etc.