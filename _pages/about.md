---
permalink: /
title: "Gang Li"
excerpt: "Gang Li"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

I am currently a Ph.D. candidate at the Institute of Software, Chinese Academy of Sciences (CAS), working on Self-supervised Learning and Diffusion Models.
In June 2025, I will obtain my Ph.D. degree from Institute of Software, Chinese Academy of Sciences.  

In response to the challenges faced by large language models, such as high computational resource demands and weak foundational theories, my research is dedicated to exploring the underlying principles of large language models. The goal is to design efficient and interpretable lightweight language models, thereby narrowing the gap between foundational theory and practical algorithms. Specific research interests include, but are not limited to:

**Lightweight Language Models**: Investigating the underlying principles of scaling guidelines for large language models to guide the design of the next generation of efficient and deployable lightweight language models. This involves technologies such as model architecture design, model compression, and high-quality instruction fine-tuning.

**LLMs and Deep Learning Theories**: Delving into the unique phenomena of large language models, such as scaling guidelines, contextual learning abilities, complex reasoning capabilities, and the underlying principles of benign overfitting and the double descent phenomenon in deep learning.

**Generalization Theories of Large-Scale Machine Learning Methods**: Researching the generalization theory of large-scale machine learning methods and using the results from generalization theory to enhance large-scale algorithms. This includes studying various methods like federated learning, distributed learning, random features, Nyström methods, sketching methods, and more.

## Curriculum Vitae 

| Time               | Title                                                       | Institution                               | Research Direction                                    |
|:-------------------| :---------------------------------------------------------- | :---------------------------------------- | :---------------------------------------------------- |
| 2019.09 - Now  | Ph.D. Candidate                                             | Institute of Software, CAS | Self-supervised Learning、Diffusion Models |
| 2015.09 - 2019.06  | Bachelor Candidate                                          | HeNan University                   | Network Engineering            |

## Selected Papers [Google Scholar](https://scholar.google.com/citations?user=StWrqHIAAAAJ&hl=en)
## Preprint
* Cartoondiff: Training-free Cartoon Image Generation with Diffusion Transformer Models.
[[pdf]](https://arxiv.org/pdf/2309.08251.pdf) <br>
Feihong He, <u><b>Gang Li</b></u>, Lingyu Si, Leilei Yan, Shimeng Hou, Hongwei Dong, Fanzhang Li.  <br>
<i> arXiv:2309.08251</i>.

* 3ddesigner: Towards photorealistic 3d object generation and editing with text-guided diffusion models.
[[pdf]](https://arxiv.org/pdf/2211.14108) <br>
<u><b>Gang Li</b></u>, Heliang Zheng, Chaoyue Wang, Chang Li, Changwen Zheng, Dacheng Tao.  <br>
<i> arXiv:2211.14108</i>.

## Publication

* Semmae: Semantic-guided masking for learning masked autoencoders.
[[pdf]](https://proceedings.neurips.cc/paper_files/paper/2022/file/5c186016d0844767209dc36e9e61441b-Paper-Conference.pdf)
[[code]](https://github.com/ucasligang/SemMAE) <br>
<u><b>Gang Li</b></u>, Heliang Zheng, Daqing Liu, Chaoyue Wang, Bing Su, Changwen Zheng. <br>
<i>Neural Information Processing Systems</i> (**NeurIPS**), 2022. <b>CCF-A conference</b>.

* Simvit: Exploring a simple vision transformer with sliding windows
[[pdf]](https://arxiv.org/pdf/2112.13085.pdf) <br>
<u><b>Gang Li</b></u>, Di Xu, Xing Cheng, Lingyu Si, Changwen Zheng. <br>
<i>IEEE International Conference on Multimedia and Expo</i> (**ICME**), 2022. <b>CCF-B </b>.

* Transductive distribution calibration for few-shot learning
[[pdf]](https://www.sciencedirect.com/science/article/abs/pii/S0925231222006634) <br>
<u><b>Gang Li</b></u>, Changwen Zheng, Bing Su. <br>
<i>Neurocomputing</i> (****), 2022. <b>CCF-C journal、SCI journal</b>.



## Honors and Awards

* Merit student of University of Chinese Academy of Sciences (UCAS), 2023.
* Outstanding member of the Communist Youth League of the University of Chinese Academy of Sciences (UCAS), 2020.
* National Encouragement Scholarship, 2018.
* National Scholarship for undergraduate students, 2017.

## Academic Service
* Program committee of Conference: ICML, NeurIPS, ICLR, AAAI, IJCAI, ICME, etc.
* Reviewers of Journals: TPAMI, JMLR, Pattern Recognition, etc.
