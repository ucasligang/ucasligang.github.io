---
title: ""
permalink: /chinese/
author_profile: true
---

**å‰¯ç ”ç©¶å‘˜ï¼ˆä¸€çº§ï¼‰ ç¡•å£«ç”Ÿå¯¼å¸ˆ ä¸­å›½ç§‘å­¦é™¢ä¿¡æ¯å·¥ç¨‹ç ”ç©¶æ‰€** 

**åœ°å€ï¼šåŒ—äº¬å¸‚æµ·æ·€åŒºæ ‘æ‘è·¯19å·ï¼Œ100085** 

**é‚®ç®±ï¼šlijian9026 [at] iie.ac.cn, superlj666 [at] gmail.com**

# ç ”ç©¶æ–¹å‘
æœ¬äººç ”ç©¶æ–¹å‘ä¸ºå¤§è§„æ¨¡ç»Ÿè®¡æœºå™¨å­¦ä¹ ï¼Œé’ˆå¯¹ä¼ ç»Ÿæœºå™¨å­¦ä¹ æ¨¡å‹ã€å¤§è¯­è¨€æ¨¡å‹è®¾è®¡è¿›è¡Œç†è®ºç†è®ºåˆ†æå¹¶è®¾è®¡é«˜æ•ˆã€å¯æ‰©å±•çš„ç®—æ³•ã€‚ä¸»è¦ç ”ç©¶å†…å®¹åŒ…æ‹¬ï¼š
- **å¤§è§„æ¨¡ç»Ÿè®¡æœºå™¨å­¦ä¹ **ï¼šä¸ºå¤§è§„æ¨¡æœºå™¨å­¦ä¹ æ–¹æ³•ï¼ˆåŒ…æ‹¬è”é‚¦å­¦ä¹ ã€åˆ†å¸ƒå¼å­¦ä¹ ã€NystrÃ¶m é‡‡æ ·ã€éšæœºç‰¹å¾ã€éšæœºæŠ•å½±ç­‰å¤§è§„æ¨¡ç®—æ³•ï¼‰ï¼Œæä¾›æ›´ç´§è‡´çš„æ³›åŒ–ç†è®ºåˆ†æå¹¶è®¾è®¡é«˜æ•ˆç®—æ³•ã€‚
- **é«˜æ•ˆå¤§è¯­è¨€æ¨¡å‹**ï¼šåŒ…æ‹¬é«˜æ•ˆ Transformerã€å¤§æ¨¡å‹å‹ç¼©æ–¹æ³•ã€å‚æ•°é«˜æ•ˆå¾®è°ƒæ–¹æ³•ã€‚
- **æ·±åº¦å­¦ä¹ åŠå¤§æ¨¡å‹ç†è®º**ï¼šä¸ºæ·±åº¦å­¦ä¹ ä¸­è‰¯å¥½è¿‡æ‹Ÿåˆã€æµ‹è¯•è¯¯å·®åŒä¸‹é™ç­‰ç°è±¡æä¾›ç†è®ºåˆ†æï¼Œå¹¶å°è¯•ç†è®ºæ¢ç´¢å¤§è¯­è¨€æ¨¡å‹çš„åŸºç¡€ç†è®ºã€‚

å…·ä½“ç ”ç©¶æ–¹æ³•ä¸ºé€šè¿‡ç†è®ºåˆ†æè®¾è®¡æ”¹è¿›å¤§è§„æ¨¡æœºå™¨å­¦ä¹ ç®—æ³•ï¼Œä»è€Œå¼¥åˆæœºå™¨å­¦ä¹ ç†è®ºã€ç®—æ³•ä¸å¤§è§„æ¨¡åº”ç”¨ä¹‹é—´çš„å·¨å¤§å·®è·ã€‚

# éƒ¨åˆ†è®ºæ–‡ [[å®Œæ•´åˆ—è¡¨](https://lijian.ac.cn/publications/)] [[è°·æ­Œå­¦æœ¯](https://scholar.google.com/citations?hl=zh-CN&user=IAJpTqYAAAAJ&view_op=list_works&sortby=pubdate)] 
<i>* é€šè®¯ä½œè€…</i>

## æœŸåˆŠè®ºæ–‡

* Optimal Convergence Rates for Distributed NystrÃ¶m Approximation. 
[[pdf]](https://jmlr.org/papers/volume24/21-1049/21-1049.pdf)
[[code]](https://github.com/superlj666/DNystroem) <br>
<b>Jian Li</b>, Yong Liu, Weiping Wang. <br>
<i>Journal of Machine Learning Research</i> (**JMLR**), 2023. <b>CCF-A journal</b>.

* Optimal Convergence for Agnostic Kernel Learning With Random Features.
[[pdf]](https://ieeexplore.ieee.org/abstract/document/10304308)
[[code]](https://github.com/superlj666/Agnostic-RF)
<br>
<b>Jian Li</b>, Yong Liu, Weiping Wang.  <br>
<i>IEEE Transactions on Neural Networks and Learning Systems</i> (**TNNLS**), 2023. <b>CCF-B journal</b>.

* Semi-supervised vector-valued learning: Improved bounds and algorithms. 
[[pdf]](https://www.sciencedirect.com/science/article/pii/S0031320323000572) <br>
<b>Jian Li</b>, Yong Liu, Weiping Wang.  <br>
<i>Pattern Recognition</i> (**PR**), 2023. <b>CCF-B journal</b>.

* Improving Differentiable Architecture Search via Self-distillation.
[[pdf]](https://doi.org/10.1016/j.neunet.2023.08.062) <br>
Xunyu Zhu, <b>Jian Li*</b>, Yong Liu, Weiping Wang.  <br>
<i>Neural Networks</i>. <b>CCF-B journal</b>.

* Convolutional Spectral Kernel Learning with Generalization Guarantees.
[[Paper]](https://doi.org/10.1016/j.artint.2022.103803)
[[Code]](https://github.com/superlj666/CSKN/) <br>
<b>Jian Li</b>, Yong Liu, Weiping Wang. <br>
<i>Artificial Intelligence</i> (**AIJ**), 2022. <b>CCF-A journal</b>.

* Non-IID Federated Learning with Sharper Risk Bound.
[[pdf]](https://doi.org/10.1109/TNNLS.2022.3213187) <br>
Bojian Wei, <b>Jian Li*</b>, Yong Liu, Weiping Wang.  <br>
<i>IEEE Transactions on Neural Networks and Learning Systems</i> (**TNNLS**), 2022. <b>CCF-B journal</b>.

## ä¼šè®®è®ºæ–‡

* Optimal Convergence Rates for Agnostic NystrÃ¶m Kernel Learning.
[[pdf]](https://openreview.net/pdf?id=S3d9SwhRKh)
<br>
<b>Jian Li</b>, Yong Liu, Weiping Wang. <br>
<i>International Conference on Machine Learning </i> (**ICML**), 2023. <b>CCF-A conference</b>.

* Towards Sharp Analysis for Distributed Learning with Random Features. [[pdf]](https://www.ijcai.org/proceedings/2023/0436.pdf) <br>
<b>Jian Li</b>, Yong Liu. <br>
<i>International Joint Conference on Artificial Intelligence</i> (**IJCAI**), 2023. <b>CCF-A conference</b>.

* Ridgeless Regression with Random Features.
[[pdf]](https://arxiv.org/pdf/2205.00477.pdf)
[[code]](https://github.com/superlj666/Ridgeless-Regression-with-Random-Features) <br>
<b>Jian Li</b>, Yong Liu, Yingying Zhang. <br>
<i>International Joint Conference on Artificial Intelligence</i> (**IJCAI**), 2022. <b>CCF-A conference</b>.

* Federated learning for non-iid data: From theory to algorithm. 
[[pdf]](https://lijian.ac.cn/files/2021/FL_for_noniid_data.pdf)
[[presentation]](https://lijian.ac.cn/files/2021/FL_for_noniid_data_presentation.pdf)
<b>[[Best student paper award]](https://lijian.ac.cn/files/2021/PRICAI-2021-best-student-paper.png)</b><br>
Bojian Wei, <b>Jian Li*</b>, Yong Liu, Weiping Wang. <br>
<i>Pacific Rim International Conference on Artificial Intelligence</i> (**PRICAI**), 2021. CCF-C conference.

* Automated Spectral Kernel Learning. 
[[pdf]](https://ojs.aaai.org/index.php/AAAI/article/view/5892/5748)
[[poster]](https://lijian.ac.cn/files/2020_AAAI_ASKL/2020_AAAI_AKSL_poster.pdf)
[[code]](https://github.com/superlj666/Automated-Spectral-Kernel-Learning) <br>
<b>Jian Li</b>, Yong Liu, Weiping Wang. <br>
<i>AAAI Conference on Artificial Intelligence</i> (**AAAI**), 2020. <b>CCF-A conference</b>.

* Multi-Class Learning: From Theory to Algorithm. 
[[pdf]](https://proceedings.neurips.cc/paper/2018/file/1141938ba2c2b13f5505d7c424ebae5f-Paper.pdf)
[[poster]](https://lijian.ac.cn/files/2018_NeurIPS_MC/mc-lrc-nips-poster.pdf)
[[sildes]](https://lijian.ac.cn/files/2018_NeurIPS_MC/mc-lrc-nips-slides.pdf)
[[3-minute video]](https://youtu.be/mE_RpgWuKK8)
[[code]](https://github.com/superlj666/Multi-Class-Learning-From-Theory-to-Algorithm) <br>
<b>Jian Li</b>, Yong Liu, Rong Yin, Hua Zhang, Lizhong Ding, Weiping Wang. <br>
<i>Advances in Neural Information Processing Systems 31</i> (**NeurIPS**), 2018. <b>CCF-A conference</b>.


# ä¸»æŒé¡¹ç›®

* ä¸­å›½åšå£«åç§‘å­¦åŸºé‡‘ï¼ˆç«™ä¸­ï¼‰ç‰¹åˆ«èµ„åŠ©é¡¹ç›® (No. 2023T160680)ï¼Œ2023.07 - 2024.03ï¼Œ18ä¸‡å…ƒã€‚ <br>
é¢å‘ç»“æ„åŒ–é¢„æµ‹çš„æ·±åº¦å¯å¾®é«˜æ–¯è¿‡ç¨‹æ–¹æ³•ç ”ç©¶ã€‚

* å›½å®¶é‡ç‚¹ç ”å‘é¡¹ç›®å­è¯¾é¢˜ (2022YFB3105302.2)ï¼Œ202201 - 2024.12ï¼Œ120ä¸‡å…ƒã€‚ <br>
è·¨å¹³å°å¼‚è´¨æ€§æ•°æ®èšåˆä¸ååŒæŠ€æœ¯ã€‚

* å›½å®¶è‡ªç„¶ç§‘å­¦åŸºé‡‘é’å¹´åŸºé‡‘ (No. 62106257)ï¼Œ30ä¸‡å…ƒã€‚ <br>
é¢å‘å¤§è§„æ¨¡ç»“æ„åŒ–é¢„æµ‹çš„è‡ªåŠ¨è°±æ ¸å­¦ä¹ ç ”ç©¶ã€‚

* ä¸­å›½ç§‘å­¦é™¢ç‰¹åˆ«ç ”ç©¶åŠ©ç†èµ„åŠ©ï¼Œ2020.09 - 2022.09ï¼Œ80ä¸‡å…ƒã€‚ <br>
å¤§è§„æ¨¡å°æ ·æœ¬è‡ªåŠ¨åŒ–æœºå™¨å­¦ä¹ ã€‚

* ä¸­å›½ç§‘å­¦é™¢ä¿¡æ¯å·¥ç¨‹ç ”ç©¶æ‰€ä¼˜æ‰è®¡åˆ’Aç±»ï¼Œ2023.11 - 2026.11ï¼Œé¢„è˜ï¼ˆæ­£é«˜çº§ï¼‰ç ”ç©¶å‘˜ã€‚

* ä¸­å›½ç§‘å­¦é™¢ä¿¡æ¯å·¥ç¨‹ç ”ç©¶æ‰€ä¼˜æ‰è®¡åˆ’Bç±»ï¼Œ2020.09 - 2023.09ï¼Œé¢„è˜ï¼ˆæ­£é«˜çº§ï¼‰ç ”ç©¶å‘˜ã€‚


# æŒ‡å¯¼å­¦ç”Ÿ
- åšå£«ç ”ç©¶ç”Ÿ
  - åº·è‰ºéœ–ï¼ˆ2018-2023ï¼‰ğŸ“ï¼Œå·®åˆ†éšç§ã€‚ å‘è¡¨è®ºæ–‡ï¼šComputers & Securityã€CIKM 2022ã€ICCS 2023ã€‚æ¯•ä¸šå»å‘ï¼šç´«é‡‘å±±å®éªŒå®¤.
  - æœ±å‹‹å®‡ï¼ˆ2020-è‡³ä»Šï¼‰ï¼Œç¥ç»ç½‘ç»œç»“æ„æœç´¢ã€‚å‘è¡¨è®ºæ–‡ï¼šICDM 2021, Neural Networksã€‚
  - è½¦åšè½©ï¼ˆ2020-è‡³ä»Šï¼‰ï¼Œé«˜æ•ˆå›¾ç¥ç»ç½‘ç»œã€‚
- ç¡•å£«ç ”ç©¶ç”Ÿ
  - éŸ¦åšèˆ°ï¼ˆ2019-2022ï¼‰ğŸ“ï¼Œè”é‚¦å­¦ä¹ ã€‚å‘è¡¨è®ºæ–‡ï¼šPRICAI 2021 (**æœ€ä½³å­¦ç”Ÿè®ºæ–‡å¥–**)ã€ECML-PKDD 2022ã€TNNLSã€IJCNN 2023ã€‚æ¯•ä¸šå»å‘ï¼šä¸­å›½é“¶è¡Œæ€»è¡Œç®¡åŸ¹ç”Ÿã€‚
  - å¼ æ—­å®ï¼ˆ2023-è‡³ä»Šï¼‰ï¼Œè”é‚¦å­¦ä¹ ã€‚**æ­¦æ±‰å¤§å­¦ä¼˜ç§€å­¦å£«è®ºæ–‡å¥–**ã€‚

# è£èª‰ç§°å·
* PRICAI 2021 æœ€ä½³å­¦ç”Ÿè®ºæ–‡å¥–ã€‚
* 2020å¹´åŒ—äº¬å¸‚ä¼˜ç§€æ¯•ä¸šç”Ÿã€‚
* 2020å¹´ä¸­å›½ç§‘å­¦é™¢å¤§å­¦ï¼ˆå›½ç§‘å¤§ï¼‰ä¼˜ç§€æ¯•ä¸šç”Ÿã€‚
* 2019å¹´åšå£«ç ”ç©¶ç”Ÿå›½å®¶å¥–å­¦é‡‘ã€‚
* 2019å¹´æœ±ææœˆåä¼˜ç§€åšå£«ç”Ÿå¥–ã€‚
* 2019å¹´ä¸­ç§‘é™¢é™¢é•¿ä¼˜ç§€å¥–ã€‚
* 2018å¹´åšå£«ç ”ç©¶ç”Ÿå›½å®¶å¥–å­¦é‡‘ã€‚
* 2018å¹´ä¸­ç§‘é™¢ä¿¡å·¥æ‰€æ‰€é•¿ä¼˜ç§€å¥–ã€‚


# ä¸ªäººå±¥å†
| <!-- -->    | <!-- -->    | <!-- -->    | <!-- -->    |
|  ----  | ----  | --- | --- |
| 2023.11 - è‡³ä»Š   | å‰¯ç ”ç©¶å‘˜ä¸€çº§ï¼Œé’å¹´é¢„è˜ç ”ç©¶å‘˜ |  ä¸­å›½ç§‘å­¦é™¢ä¿¡æ¯å·¥ç¨‹ç ”ç©¶æ‰€ | å¤§è§„æ¨¡ç»Ÿè®¡æœºå™¨å­¦ä¹ , å¤§è¯­è¨€æ¨¡å‹|
| 2020.09 - 2023.11  | åŠ©ç†ç ”ç©¶å‘˜ï¼Œåšå£«åï¼Œé’å¹´é¢„è˜ç ”ç©¶å‘˜ | ä¸­å›½ç§‘å­¦é™¢ä¿¡æ¯å·¥ç¨‹ç ”ç©¶æ‰€ | å¤§è§„æ¨¡ç»Ÿè®¡æœºå™¨å­¦ä¹  |
| 2015.09 - 2020.07  | ç¡•åšè¿è¯»ç ”ç©¶ç”Ÿ | ä¸­å›½ç§‘å­¦é™¢ä¿¡æ¯å·¥ç¨‹ç ”ç©¶æ‰€ | å¤§è§„æ¨¡æ¨¡å‹é€‰æ‹©ï¼ŒåŠç›‘ç£å­¦ä¹  |
| 2011.09 - 2020.07  | æœ¬ç§‘ç”Ÿ | ä¸œåŒ—å¤§å­¦ | è½¯ä»¶å·¥ç¨‹ï¼ˆè‹±è¯­å›½é™…ç­ï¼‰|

# å­¦æœ¯æœåŠ¡
- ç¨‹åºå§”å‘˜æˆ–å®¡ç¨¿äºº
  - ä¼šè®®ï¼šICMLã€NeurIPSã€ICLRã€AAAIã€IJCAIã€ECAI
  - æœŸåˆŠï¼šTPAMIã€JMLRã€Pattern Recognition