---
title: ""
permalink: /chinese/
author_profile: true
---

我目前是中国科学院软件研究所的博士研究生，研究方向为自监督学习与扩散模型。
预计于2025年6月获得中国科学院软件研究所博士学位。我很荣幸将加入荣耀公司MagicOS事业部的智慧视觉平台团队，担任高级计算机视觉算法工程师。在此之前，我曾在快手MMU和京东探索研究院担任算法实习生。目前主要聚焦多模态理解与AIGC（人工智能生成内容）技术的研发工作。我们团队正在招募实习生和全职研究员/工程师，如果您对这些前沿领域的机会感兴趣，欢迎将简历发送至ucasligang[at]gmail[dot]com。

当前我的研究兴趣集中在多模态理解与AIGC（人工智能生成内容）领域，具体包括但不限于：

**大型多模态模型**

**可控生成扩散模型**

**生成扩散模型的高效训练与采样**

此前我主要研究掩码图像建模（MIM）和视觉Transformer（ViT）方向。值得一提的是，我们在GitHub上维护了一个关于掩码图像建模（MIM）的论文列表仓库，目前已获得300+星标。项目链接：[awesome-MIM](https://github.com/ucasligang/awesome-MIM)

## 学术履历

| 时间               | 学位/职位                                                  | 机构                                   | 研究方向                                    |
|:-------------------| :---------------------------------------------------------- | :------------------------------------- | :------------------------------------------ |
| 2019.09 - 至今    | 博士研究生                                                 | 中国科学院软件研究所         | 自监督学习、扩散模型          |
| 2015.09 - 2019.06 | 学士学位                                                   | 河南大学                           | 网络工程                      |

## 精选论文 [[Google Scholar完整列表]](https://scholar.google.com/citations?user=StWrqHIAAAAJ&hl=zh-CN)
### 预印本
* FreeStyle: Free Lunch for Text-guided Style Transfer using Diffusion Models
[[pdf]](https://arxiv.org/pdf/2401.15636.pdf) [[Project page]](https://freestylefreelunch.github.io/) <br>
Feihong He, <u><b>Gang Li</b></u>, Mengyuan Zhang, Leilei Yan, Lingyu Si, Fanzhang Li.  <br>
<i> arXiv:2401.15636</i>.

* 3ddesigner: Towards photorealistic 3d object generation and editing with text-guided diffusion models.
[[pdf]](https://arxiv.org/pdf/2211.14108) [[Project page]](https://3ddesigner-diffusion.github.io/) <br> 
<u><b>Gang Li</b></u>, Heliang Zheng, Chaoyue Wang, Chang Li, Changwen Zheng, Dacheng Tao.  <br>
<i> arXiv:2211.14108</i>.

### 已发表论文

* Semmae: Semantic-guided masking for learning masked autoencoders.
[[pdf]](https://proceedings.neurips.cc/paper_files/paper/2022/file/5c186016d0844767209dc36e9e61441b-Paper-Conference.pdf)
[[code]](https://github.com/ucasligang/SemMAE) <br>
<u><b>Gang Li</b></u>, Heliang Zheng, Daqing Liu, Chaoyue Wang, Bing Su, Changwen Zheng. <br>
<i>Neural Information Processing Systems</i> (**NeurIPS**), 2022. <b>CCF-A </b>.

* DreamBooth++: Boosting Subject-Driven Generation via Region-Level References Packing.
[[pdf]](https://openreview.net/pdf?id=06c7e989wH) <br>
Zhongyi Fan, Zixin Yin, <u><b>Gang Li</b></u>, Yibing Zhan, Heliang Zheng. <br>
<i>Proceedings of the 32nd ACM International Conference on Multimedia</i> (**ACM MM**), 2024. <b>CCF-A </b>.

* Simvit: Exploring a simple vision transformer with sliding windows
[[pdf]](https://arxiv.org/pdf/2112.13085.pdf) [[code]](https://github.com/ucasligang/SimViT) <br>
<u><b>Gang Li</b></u>, Di Xu, Xing Cheng, Lingyu Si, Changwen Zheng. <br>
<i>IEEE International Conference on Multimedia and Expo</i> (**ICME**), 2022. <b>CCF-B Oral</b>.

* Transductive distribution calibration for few-shot learning
[[pdf]](https://www.sciencedirect.com/science/article/abs/pii/S0925231222006634) <br>
<u><b>Gang Li</b></u>, Changwen Zheng, Bing Su. <br>
<i>Neurocomputing</i> (****), 2022. <b>CCF-C、SCI </b>.

* Cartoondiff: Training-free Cartoon Image Generation with Diffusion Transformer Models.
[[pdf]](https://arxiv.org/pdf/2309.08251.pdf)
 [[Project page]](https://cartoondiff.github.io/) [[Code]](https://github.com/CartoonDiff/CartoonDiff) <br>
Feihong He, <u><b>Gang Li</b></u>, Lingyu Si, Leilei Yan, Shimeng Hou, Hongwei Dong, Fanzhang Li.  <br>
<i>IEEE International Conference on Acoustics, Speech and Signal Processing</i> (**ICASSP**), 2024. <b>CCF-B</b>.



## 荣誉和获奖情况

* 中国科学院大学一等学业奖学金, 2024.
* 中国科学院大学三好学生, 2023, 2024.
* "中国科学院第十九届公众科学日"优秀志愿者, 2020.
* 本科国家励志奖学金, 2018.
* 本科国家奖学金, 2017.
